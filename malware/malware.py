import csv
import os

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import keras.backend as K

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall


def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision


def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))

csv_path = os.path.join('Dataset/dataset.csv')

labels = []
data = []
cont = 0
with open(csv_path) as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for row in csv_reader:
        if "malicious" in row[0]:
            labels.append(1)
        else:
            labels.append(0)
        data_r = [float(x) for x in row[1:]]
        data.append(data_r)
        cont += 1
        if cont %10000==0: print(cont)

# 0-100k malicious rest legit
train_labels = labels[:90000] + labels[110000:]
train_data = data[:90000] + data[110000:]
test_labels = labels[90000:110000]
test_data = data[90000:110000]

input_dim = len(train_data[0])
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(input_dim,)),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# print(model.summary())

csv_logger = CSVLogger('log.csv')
early_stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, mode='min', restore_best_weights=True)
mc = ModelCheckpoint('malware.h5', monitor='val_loss', mode='min', verbose=1)
model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc', f1_m, precision_m, recall_m, tf.keras.metrics.AUC()])

history = model.fit(x=train_data, y=train_labels, batch_size=512, epochs=15,
                    validation_data=(test_data, test_labels),
                    verbose=2,
                    callbacks=[csv_logger, mc, early_stop])


# Plot training and test acc and loss
# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
